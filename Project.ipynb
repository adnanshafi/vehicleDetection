{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Vehicle Detection**\n",
    "---\n",
    "*Pipeline to detect vehicles in a video stream using machine learning.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Imports**\n",
    " - *Import all the necessary libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from scipy.ndimage.measurements import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - Convert from one color space to another easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_space(img, space, bgr_input=True):\n",
    "    \"\"\"\n",
    "        Convert color space of image.\n",
    "    \"\"\"\n",
    "    if bgr_input:\n",
    "        if space == 'rgb':\n",
    "            convert = cv2.COLOR_BGR2RGB\n",
    "        elif space == 'hsv':\n",
    "            convert = cv2.COLOR_BGR2HSV\n",
    "        elif space == 'hls':\n",
    "            convert = cv2.COLOR_BGR2HLS\n",
    "        elif space == 'luv':\n",
    "            convert = cv2.COLOR_BGR2LUV\n",
    "        elif space == 'ycb':\n",
    "            convert = cv2.COLOR_BGR2YCrCb\n",
    "        else:\n",
    "            assert False, \"Use one of 'rgb','hsv','hls','luv', 'ycb'(YCrCb)\"\n",
    "    if not bgr_input:\n",
    "        if space == 'rgb':\n",
    "            return np.copy(img)\n",
    "        elif space == 'hsv':\n",
    "            convert = cv2.COLOR_RGB2HSV\n",
    "        elif space == 'hls':\n",
    "            convert = cv2.COLOR_RGB2HLS\n",
    "        elif space == 'luv':\n",
    "            convert = cv2.COLOR_RGB2LUV\n",
    "        elif space == 'ycb':\n",
    "            convert = cv2.COLOR_RGB2YCrCb\n",
    "        else:\n",
    "            assert False, \"Use one of 'rgb','hsv','hls','luv', 'ycb'(YCrCb)\"\n",
    "    return cv2.cvtColor(img, convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Helper Functions**\n",
    "\n",
    "---\n",
    "   - Get HOG features of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, hogD):\n",
    "    return hogD.compute(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "   - Spatial Binning of color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(image, size=(32,32)):\n",
    "    return cv2.resize(image, size).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - Color Historgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - Extract Features from a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract(img, hogD=None, space='rgb', spatial_size=(32,32), hist_bins = 32, hog_ch='r', hog_all_ch=True,\n",
    "            spatial=True, hog=True, hist=True, bgr_input=True):\n",
    "    \"\"\"Extract Features of a Single image\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Convert to desired color space\n",
    "    image = convert_space(img, space, bgr_input)\n",
    "    \n",
    "    # If spatial features should be included\n",
    "    if spatial:\n",
    "        features.append(bin_spatial(image, spatial_size))\n",
    "    if hist:\n",
    "        features.append(color_hist(image, nbins=hist_bins))\n",
    "    if hog:\n",
    "        if hog_all_ch:\n",
    "            hog_features = []\n",
    "            for ch in range(3):\n",
    "                hog_features.append(get_hog_features(image[:,:,ch], hogD))\n",
    "            features.append(np.ravel(hog_features))\n",
    "        else:\n",
    "            ch = space.find(hog_ch)\n",
    "            if ch != -1:\n",
    "                hog_features.append(get_hog_features(image[:,:,ch], hogD))\n",
    "            else :\n",
    "                assert False, \"Hog channel should be in color space eg r is in rgb, For YCrCb, ycb, c = Cr, b=Cb\"\n",
    "            features.append(np.ravel(hog_features))\n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - Extract Features from a list of files:\n",
    " - Used to train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_from_files(files, **params):\n",
    "    features = []\n",
    "    for file in files:\n",
    "        image = cv2.imread(file)\n",
    "        features.append(extract(image, **params))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - Function to draw boxes on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 255, 0), thick=6):\n",
    "    imcopy = np.copy(img)\n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Define parameters to extract Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getHogD():\n",
    "    \"\"\"\n",
    "        Get OpenCV Hog Descriptor to use to extract HOG features. \n",
    "        HOG parameters like Block size, cellsize, orientations are defined here\n",
    "    \"\"\"\n",
    "    winSize = (64,64)\n",
    "    blockSize = (16,16)\n",
    "    blockStride = (8,8)\n",
    "    cellSize = (8,8)\n",
    "    nbins = 9\n",
    "    derivAperture = 1\n",
    "    winSigma = 4.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 2.0000000000000001e-01\n",
    "    gammaCorrection = 0\n",
    "    nlevels = 64\n",
    "    return cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,\n",
    "                            histogramNormType,L2HysThreshold,gammaCorrection,nlevels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - Define Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the HOG descriptor and define training parameters\n",
    "# ycb = YCrCb\n",
    "hogD = getHogD()\n",
    "params = {\n",
    "    'space':'ycb',\n",
    "    'spatial_size':(32,32),\n",
    "    'hist_bins':64,\n",
    "    'hog_ch':'c',\n",
    "    'hog_all_ch':True,\n",
    "    'spatial':True,\n",
    "    'hist':True,\n",
    "    'hog':True,\n",
    "    'hogD' : hogD,\n",
    "    'bgr_input':True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - Function to Read the training data and split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getTrainTestData(**params):\n",
    "    \"\"\"\n",
    "        1. Reads the training images.\n",
    "        2. Extracts Feature vectors.\n",
    "        3. Compute a StandardScaler to scale the training data to zero mean and unit variance.\n",
    "        4. Save the scaler for future use.\n",
    "        5. Split the training Data into training and test sets\n",
    "    \"\"\"\n",
    "    t1 = time.time()\n",
    "    # Read images\n",
    "    car_files = glob.glob('./data/vehicles/*/*.png')\n",
    "    not_car_files = glob.glob('./data/non-vehicles/*/*.png')\n",
    "    \n",
    "    # Extract Features \n",
    "    f_cars = extract_from_files(car_files, **params)\n",
    "    f_not_cars = extract_from_files(not_car_files, **params)\n",
    "    \n",
    "    # Compute the scaler from feature vectors after concatenating them\n",
    "    X = np.vstack((f_cars, f_not_cars)).astype(np.float32)\n",
    "    y = np.hstack((np.ones(len(f_cars)), np.zeros(len(f_not_cars))))\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    \n",
    "    # Save the scaler for future use\n",
    "    joblib.dump(X_scaler, 'scaler.p')\n",
    "    \n",
    "    # Scale the training feature vectors\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    \n",
    "    # Shuffle and split the data \n",
    "    random_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=random_state)\n",
    "    print (\"Extracting Features took : %.2f Seconds\"  % (time.time() - t1))\n",
    "    return X_train, X_test, y_train, y_test, X_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " - Get the scaled training data and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features took : 33.98 Seconds\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_scaler = getTrainTestData(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8556,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 99.30%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training took : 6.345 seconds'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "# Get a linear Support Vector Machine Classifier\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Fit the training data\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Compute accuracy\n",
    "score = svc.score(X_test, y_test) * 100\n",
    "t2 = time.time()\n",
    "\n",
    "print (\"Accuracy : %.2f%%\" % score)\n",
    "\n",
    "# Save the classifier for future use. \n",
    "joblib.dump(svc, 'clf.p')\n",
    "\"Training took : %.3f seconds\" % (t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "svc = joblib.load('./clf.p')\n",
    "X_scaler = joblib.load('./scaler.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,255,0), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    \n",
    "    # Start window start stops to whole image if not specified\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    \n",
    "    # length of x and y sides of image to be searched\n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    \n",
    "    \n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    \n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    \n",
    "    # Calculate number of windows in each direction\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    \n",
    "    window_list = []\n",
    "    \n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class HeatMaps():\n",
    "    \"\"\"\n",
    "        Class to hold previous heatmaps\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer):\n",
    "        self.maps = []\n",
    "        self.num_maps = len(self.maps)\n",
    "        self.buffer_size = buffer\n",
    "    \n",
    "    def addHeatMap(self, heatmap):\n",
    "        \"\"\"Add a new heatmap\"\"\"\n",
    "        self.maps.append(heatmap)\n",
    "        self.num_maps = len(self.maps)\n",
    "        if self.num_maps > self.buffer_size:\n",
    "            self.maps.pop(0)\n",
    "    \n",
    "    def getHeatMap(self):\n",
    "        \"\"\"Get sum of last n heatmaps\"\"\"\n",
    "        if self.num_maps > 0:\n",
    "            return np.sum(self.maps, axis=0)\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HeatMap = HeatMaps(12) \n",
    "def process(image):\n",
    "    \"\"\"\n",
    "        Finds cars in individual frames of the image by applying a sliding window search. \n",
    "        Input image is expected in RGB space. After classifying individual frames, Heat maps are \n",
    "        generated and saved. Thresholding is applied to remove false positives.\n",
    "    \"\"\"\n",
    "    # Hold the windows with positive matches\n",
    "    hits = []\n",
    "    global video_params\n",
    "    global HeatMap\n",
    "    # Get the windows to search in \n",
    "    windows = []\n",
    "    windows += slide_window(image, y_start_stop=[528,656], xy_window=(128,128), xy_overlap=(0.5, 0.5))\n",
    "    windows += slide_window(image, y_start_stop=[400,656], xy_window=(96,96), xy_overlap=(0.7, 0.7))\n",
    "    windows += slide_window(image, y_start_stop=[400,464], xy_window=(64,64), xy_overlap=(0.5, 0.5))\n",
    "    # Get a blank heatmap\n",
    "    heatmap = np.zeros_like(image[:,:,0])\n",
    "    \n",
    "    for window in windows:\n",
    "        # Classify individual windows\n",
    "        cutout = image[window[0][1]:window[1][1], window[0][0]:window[1][0]]\n",
    "        cutout = cv2.resize(cutout, (64,64))\n",
    "        fv = X_scaler.transform(extract(cutout, **video_params))\n",
    "        if svc.predict(fv) == 1:\n",
    "            # If positive match, add to hits\n",
    "            hits.append(window)\n",
    "    \n",
    "    # add heat to heatmap in positive windows \n",
    "    for box in hits:\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    \n",
    "    # Save heatmap for future frames\n",
    "    HeatMap.addHeatMap(heatmap)\n",
    "    \n",
    "    if HeatMap.num_maps >2:\n",
    "        # Get the heatmaps from past to remove jitter\n",
    "        heatmap = HeatMap.getHeatMap()\n",
    "    else :\n",
    "        # Use a smaller threshold if Just getting started\n",
    "        heatmap[heatmap<3] = 0 \n",
    "    \n",
    "    # Threshold the heatmap\n",
    "    heatmap[heatmap<9] = 0\n",
    "    \n",
    "    # Get the bounding boxes \n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    # Draw the bounding boxes on original Frame\n",
    "    return draw_labeled_bboxes(image, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define parameters for frames from video as video frames are RGB\n",
    "video_params = params.copy()\n",
    "video_params['bgr_input'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [09:38<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 30s, sys: 7.01 s, total: 9min 37s\n",
      "Wall time: 9min 39s\n"
     ]
    }
   ],
   "source": [
    "HeatMap = HeatMaps(12) \n",
    "output = './out3.mp4'\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "clip1 = clip1.subclip(0)\n",
    "white_clip = clip1.fl_image(process) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./out3.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "output = './out3.mp4'\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
